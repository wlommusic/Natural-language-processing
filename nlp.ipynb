{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOtislH1PcX2"
      },
      "source": [
        "# Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B-UCf09Pfv0"
      },
      "source": [
        "##Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzgIkXcUPVTp"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import nltk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj1JfRBEPssF"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPRcKa4gPvGc"
      },
      "source": [
        "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODyVGBUbPya-"
      },
      "source": [
        "###Cleaning the texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3YJSe50P3Um",
        "outputId": "51a2889e-eb4c-4bd3-d3a0-da65498c831f"
      },
      "source": [
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "corpus = []\r\n",
        "for i in range(0, 1000):\r\n",
        "  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\r\n",
        "  review = review.lower()\r\n",
        "  review = review.split()\r\n",
        "  ps = PorterStemmer()\r\n",
        "  all_stopwords = stopwords.words('english')\r\n",
        "  all_stopwords.remove('not')\r\n",
        "  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\r\n",
        "  review = ' '.join(review)\r\n",
        "  corpus.append(review)\r\n",
        "# print(corpus)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c13KfbMfQIDv"
      },
      "source": [
        "### Creating the Bag of Words model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vohSPEUjQL26"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "cv = CountVectorizer(max_features = 1500)\r\n",
        "X = cv.fit_transform(corpus).toarray()\r\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0SSJGgrQRs0"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNrZi_XyQSgJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1UHAiV9QWvo"
      },
      "source": [
        "### Training the Naive Bayes model on the Training set\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEYSAa7WXChA",
        "outputId": "4b5ca2fb-af5b-49df-814f-685f2eda3b6e"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "classifier1 = GaussianNB()\r\n",
        "classifier1.fit(X_train, y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDBHChOKXFG9"
      },
      "source": [
        "##Training the SGDC model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHd7jx-ZT3mJ",
        "outputId": "38c45397-8fe7-43a0-cbde-636854b911ae"
      },
      "source": [
        " from sklearn.linear_model import SGDClassifier\r\n",
        " classifier2 = SGDClassifier(random_state=42)\r\n",
        " classifier2.fit(X_train,y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQFxVSR6XN3e"
      },
      "source": [
        "##Training the Gridsearch  model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjvcBA-FVJOl",
        "outputId": "d162f3bf-4d9f-4a13-e594-e216b5e91bd4"
      },
      "source": [
        "from sklearn import svm\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "svc = svm.SVC()\r\n",
        "classifier3 = GridSearchCV (estimator=svc,param_grid={'kernel': ('linear', 'rbf')})\r\n",
        "classifier3.fit(X_train,y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'kernel': ('linear', 'rbf')}, pre_dispatch='2*n_jobs',\n",
              "             refit=True, return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRcNy4wzRAjr"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUiT_iwbRD2u"
      },
      "source": [
        "y_pred1 = classifier1.predict(X_test)\r\n",
        "# print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "admq6K3WXfr6"
      },
      "source": [
        "y_pred2 = classifier2.predict(X_test)\r\n",
        "# print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWtmwuFYXft5"
      },
      "source": [
        "y_pred3 = classifier3.predict(X_test)\r\n",
        "# print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkipc-h8RHRj"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DbKS-HhRI6h",
        "outputId": "11dacdf3-e22b-43b6-8695-1f332fbf8d81"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "cm = confusion_matrix(y_test, y_pred1)\r\n",
        "print(cm)\r\n",
        "print(accuracy_score(y_test, y_pred1))\r\n",
        "print('Naive bayes')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[54 43]\n",
            " [12 91]]\n",
            "0.725\n",
            "Naive bayes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f44acxUMXroZ",
        "outputId": "c325d137-ca2d-4415-940f-b04285cd07a4"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "cm = confusion_matrix(y_test, y_pred2)\r\n",
        "print(cm)\r\n",
        "print(accuracy_score(y_test, y_pred2))\r\n",
        "print('SGDclassifier')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[81 16]\n",
            " [30 73]]\n",
            "0.77\n",
            "SGDclassifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRLSEasWXrqb",
        "outputId": "4ea0a70c-e0a1-4cc5-c1dc-a3b7e18e883d"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "cm = confusion_matrix(y_test, y_pred3)\r\n",
        "print(cm)\r\n",
        "print(accuracy_score(y_test, y_pred3))\r\n",
        "print('Grid search')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[87 10]\n",
            " [36 67]]\n",
            "0.77\n",
            "Grid search\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8E8cHPTRLJJ"
      },
      "source": [
        "###single preds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsQbuqDyROU6",
        "outputId": "60e1764d-eb1f-48e8-f104-3c51f1f71758"
      },
      "source": [
        "new_review = \" good dont buy this product please but this good product but dont but nice\"\r\n",
        "new_review = re.sub('[^a-zA-Z]', ' ', new_review)\r\n",
        "new_review = new_review.lower()\r\n",
        "new_review = new_review.split()\r\n",
        "ps = PorterStemmer()\r\n",
        "all_stopwords = stopwords.words('english')\r\n",
        "all_stopwords.remove('not')\r\n",
        "new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\r\n",
        "new_review = ' '.join(new_review)\r\n",
        "new_corpus = [new_review]\r\n",
        "new_X_test = cv.transform(new_corpus).toarray()\r\n",
        "new_y_pred = classifier2.predict(new_X_test)\r\n",
        "print(new_y_pred)\r\n",
        "if new_y_pred == 0:\r\n",
        "  print('Bad review')\r\n",
        "else:\r\n",
        "  print('Good review')  "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "Good review\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}